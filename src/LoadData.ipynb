{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wilds import\n",
    "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "from wilds import get_dataset\n",
    "\n",
    "# misc\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torchvision transforms\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAMELYON DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datensatz camelyon laden\n",
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "camelyon = get_dataset(dataset=\"camelyon\",download=False)\n",
    "\n",
    "img_size = (96,96)\n",
    "\"\"\" GET SPLITS & TRANSFORM DATA\"\"\"\n",
    "# Get the training set (in distribution)\n",
    "train_data = camelyon.get_subset(\"train\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# Get the validation set (out of distribution)\n",
    "val_data = camelyon.get_subset(\"val\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# Get the test set (out of distribution)\n",
    "test_data = camelyon.get_subset(\"test\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of TRAIN \n",
    "N=train_data.__len__()\n",
    "train_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(train_data,range(N)) if i <N],axis=0)\n",
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of VAL \n",
    "N=val_data.__len__()\n",
    "val_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(val_data,range(N)) if i <N],axis=0)\n",
    "val_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of TEST\n",
    "N=test_data.__len__()\n",
    "test_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(test_data,range(N)) if i <N],axis=0)\n",
    "test_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TRAIN\n",
    "with open('camelyon_train_ds.npy', 'wb') as f:\n",
    "    np.save(f,train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save VAL\n",
    "with open('camelyon_val_ds.npy', 'wb') as f:\n",
    "    np.save(f,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TEST\n",
    "with open('camelyon_test_ds.npy', 'wb') as f:\n",
    "    np.save(f,test_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLOBALWHEAT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/image-drift-monitoring\n"
     ]
    }
   ],
   "source": [
    "# datensatz globalwheat laden\n",
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "global_wheat = get_dataset(dataset=\"globalwheat\",download=False)\n",
    "\n",
    "img_size = (96,96)\n",
    "\"\"\" GET SPLITS & TRANSFORM DATA\"\"\"\n",
    "# Get the training set (in distribution)\n",
    "train_data = global_wheat.get_subset(\"train\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# # Get the validation set (out of distribution)\n",
    "# val_data = global_wheat.get_subset(\"val\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# # Get the test set (out of distribution)\n",
    "test_data = global_wheat.get_subset(\"test\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2943, 3, 96, 96)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get numpy arrays of TRAIN \n",
    "N=train_data.__len__()\n",
    "train_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(train_data,range(N)) if i <N],axis=0)\n",
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of VAL \n",
    "N=val_data.__len__()\n",
    "val_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(val_data,range(N)) if i <N],axis=0)\n",
    "val_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1434, 3, 96, 96)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get numpy arrays of TEST\n",
    "N=test_data.__len__()\n",
    "test_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(test_data,range(N)) if i <N],axis=0)\n",
    "test_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TRAIN\n",
    "np.savez_compressed('globalwheat_96_train_ds.npz',train_ds)\n",
    "# with open('globalwheat_train_ds.npy', 'wb') as f:\n",
    "#     np.save(f,train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save VAL\n",
    "np.savez_compressed('globalwheat_val_ds.npz',val_ds)\n",
    "# with open('globalwheat_val_ds.npy', 'wb') as f:\n",
    "#     np.save(f,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TEST\n",
    "np.savez_compressed('globalwheat_96_test_ds.npz',test_ds)\n",
    "# with open('globalwheat_test_ds.npy', 'wb') as f:\n",
    "#     np.save(f,test_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IWILDCAM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/image-drift-monitoring\n"
     ]
    }
   ],
   "source": [
    "# datensatz iwildcam laden\n",
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "iwildcam = get_dataset(dataset=\"iwildcam\",download=False)\n",
    "\n",
    "img_size = (96,96)\n",
    "\"\"\" GET SPLITS & TRANSFORM DATA\"\"\"\n",
    "# Get the training set (in distribution)\n",
    "train_data = iwildcam.get_subset(\"train\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# # Get the validation set (out of distribution)\n",
    "val_data = iwildcam.get_subset(\"val\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# # Get the test set (out of distribution)\n",
    "test_data = iwildcam.get_subset(\"test\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129809, 3, 96, 96)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get numpy arrays of TRAIN \n",
    "N=train_data.__len__()\n",
    "train_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(train_data,range(N)) if i <N],axis=0)\n",
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of VAL \n",
    "N=val_data.__len__()\n",
    "val_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(val_data,range(N)) if i <N],axis=0)\n",
    "val_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42791, 3, 96, 96)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get numpy arrays of TEST\n",
    "N=test_data.__len__()\n",
    "test_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(test_data,range(N)) if i <N],axis=0)\n",
    "test_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TRAIN\n",
    "np.savez_compressed('iwildcam_96_train_ds.npz',train_ds)\n",
    "# with open('iwildcam_train_ds.npy', 'wb') as f:\n",
    "#     np.save(f,train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save VAL\n",
    "np.savez_compressed('iwildcam_val_ds.npz',val_ds)\n",
    "# with open('iwildcam_val_ds.npy', 'wb') as f:\n",
    "#     np.save(f,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TEST\n",
    "np.savez_compressed('iwildcam_96_test_ds.npz',test_ds)\n",
    "# with open('iwildcam_test_ds.npy', 'wb') as f:\n",
    "#     np.save(f,test_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RXRX1 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/image-drift-monitoring\n"
     ]
    }
   ],
   "source": [
    "# datensatz RXRX1 laden\n",
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "rxrx1 = get_dataset(dataset=\"rxrx1\",download=False)\n",
    "\n",
    "img_size = (96,96)\n",
    "\"\"\" GET SPLITS & TRANSFORM DATA\"\"\"\n",
    "# Get the training set (in distribution)\n",
    "train_data = rxrx1.get_subset(\"train\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# # Get the validation set (out of distribution)\n",
    "# val_data = rxrx1.get_subset(\"val\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# # Get the test set (out of distribution)\n",
    "test_data = rxrx1.get_subset(\"test\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40612, 3, 96, 96)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get numpy arrays of TRAIN \n",
    "N=train_data.__len__()\n",
    "train_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(train_data,range(N)) if i <N],axis=0)\n",
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of VAL \n",
    "N=val_data.__len__()\n",
    "val_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(val_data,range(N)) if i <N],axis=0)\n",
    "val_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34432, 3, 96, 96)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get numpy arrays of TEST\n",
    "N=test_data.__len__()\n",
    "test_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(test_data,range(N)) if i <N],axis=0)\n",
    "test_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TRAIN\n",
    "np.savez_compressed('rxrx1_96_train_ds.npz',train_ds)\n",
    "# with open('rxrx1_train_ds.npy', 'wb') as f:\n",
    "#     np.save(f,train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save VAL\n",
    "np.savez_compressed('rxrx1_val_ds.npz',val_ds)\n",
    "# with open('rxrx1_val_ds.npy', 'wb') as f:\n",
    "#     np.save(f,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TEST\n",
    "np.savez_compressed('rxrx1_96_test_ds.npz',test_ds)\n",
    "# with open('rxrx1_test_ds.npy', 'wb') as f:\n",
    "#     np.save(f,test_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "camelyon_train = np.load('camelyon_train_ds.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camelyon_train['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "with open('camelyon_train_ds.npy','rb') as f:\n",
    "    data = np.load(f)\n",
    "    np.savez_compressed('camelyon_train_ds.npz',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('camelyon_test_ds.npz',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.load('camelyon_test_ds.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['arr_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data2['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.transpose(tmp[0],(1,2,0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POVERTY TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datensatz poverty laden\n",
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "rxrx1 = get_dataset(dataset=\"poverty\",download=False)\n",
    "\n",
    "img_size = (100,100)\n",
    "\"\"\" GET SPLITS & TRANSFORM DATA\"\"\"\n",
    "# Get the training set (in distribution)\n",
    "train_data = rxrx1.get_subset(\"train\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# Get the validation set (out of distribution)\n",
    "val_data = rxrx1.get_subset(\"val\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))\n",
    "\n",
    "# Get the test set (out of distribution)\n",
    "test_data = rxrx1.get_subset(\"test\",transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =train_data.dataset[10][0].numpy()\n",
    "\n",
    "test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test[:3]\n",
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = [1,2,3,4,5,6,7,8,9]\n",
    "xy_cut = xy[:3]\n",
    "xy_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((2,3,4))\n",
    "x = y[:1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([[\n",
    "    [1,2],[3,4]\n",
    "    ],\n",
    "    [\n",
    "    [5,6],[7,8]   \n",
    "    ],\n",
    "    [\n",
    "    [9,10],[11,12]   \n",
    "    ]])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.array([z[2],z[0],z[1]])\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = np.array([test2[2],test2[0],test2[1]])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.transpose(test2,(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of TRAIN \n",
    "N=train_data.__len__()\n",
    "train_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(train_data,range(N)) if i <N],axis=0)\n",
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of VAL \n",
    "N=val_data.__len__()\n",
    "val_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(val_data,range(N)) if i <N],axis=0)\n",
    "val_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays of TEST\n",
    "N=test_data.__len__()\n",
    "test_ds = np.stack([tensor[0].numpy() for tensor, i in  zip(test_data,range(N)) if i <N],axis=0)\n",
    "test_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TRAIN\n",
    "np.savez_compressed('poverty_train_ds.npz',train_ds)\n",
    "# with open('rxrx1_train_ds.npy', 'wb') as f:\n",
    "#     np.save(f,train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save VAL\n",
    "np.savez_compressed('poverty_val_ds.npz',val_ds)\n",
    "# with open('rxrx1_val_ds.npy', 'wb') as f:\n",
    "#     np.save(f,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TEST\n",
    "np.savez_compressed('poverty_test_ds.npz',test_ds)\n",
    "# with open('rxrx1_test_ds.npy', 'wb') as f:\n",
    "#     np.save(f,test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibitorchwhy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "401cebfcb5cce5f71138843ad74eb16632e47d40b3a47aa4ad883b3d134173ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
