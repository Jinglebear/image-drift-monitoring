{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace \\<Datasetname\\> for each Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KS init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "iwildcam_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/iwildcam_v2.0/96_by_96_transform/iwildcam_96_train_ds.npz')\n",
    "iwildcam_train_i = iwildcam_train_i_comp['arr_0']\n",
    "\n",
    "size_train = iwildcam_train_i.shape[0]\n",
    "\n",
    "if(size_train > 5000):\n",
    "        print('over 5000')\n",
    "        np.random.shuffle(iwildcam_train_i)\n",
    "        for i in ['KS','CVM','MMD','LSDD']:\n",
    "                np.random.shuffle(iwildcam_train_i)\n",
    "                # do 50 50 split\n",
    "                iwildcam_train_i_0_50 =  iwildcam_train_i[:5000]\n",
    "                size_training_set = iwildcam_train_i_0_50.shape[0]\n",
    "\n",
    "                print(size_training_set)\n",
    "                \n",
    "                iwildcam_train_i_50_100 = iwildcam_train_i[5000:]\n",
    "                size_remaining = iwildcam_train_i_50_100.shape[0]\n",
    "\n",
    "                print(size_remaining)\n",
    "\n",
    "                iwildcam_train_i_0_50 = torch.as_tensor(iwildcam_train_i_0_50)\n",
    "                \n",
    "                iwildcam_train_i_0_50_dl = DataLoader(TensorDataset(iwildcam_train_i_0_50,iwildcam_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "                myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "                myTAE.init_default_pt_autoencoder(iwildcam_train_i_0_50_dl)\n",
    "                myTAE.init_detector(detector_type='{}'.format(i),reference_data=iwildcam_train_i_50_100,detector_name='iwildcam_TAE_{}_{}_{}'.format(size_training_set,size_remaining,i),save_dec=True)\n",
    "\n",
    "\n",
    "else:\n",
    "        for i in ['KS','CVM','MMD','LSDD']:\n",
    "                np.random.shuffle(iwildcam_train_i)\n",
    "                # do 50 50 split\n",
    "                iwildcam_train_i_0_50 =  iwildcam_train_i[:int(iwildcam_train_i.shape[0]*0.5)]\n",
    "                size_training_set = iwildcam_train_i_0_50.shape[0]\n",
    "\n",
    "                print(size_training_set)\n",
    "                \n",
    "                iwildcam_train_i_50_100 = iwildcam_train_i[int(iwildcam_train_i.shape[0]*0.5):]\n",
    "                size_remaining = iwildcam_train_i_50_100.shape[0]\n",
    "\n",
    "                print(size_remaining)\n",
    "\n",
    "                iwildcam_train_i_0_50 = torch.as_tensor(iwildcam_train_i_0_50)\n",
    "                \n",
    "                iwildcam_train_i_0_50_dl = DataLoader(TensorDataset(iwildcam_train_i_0_50,iwildcam_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "                myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "                myTAE.init_default_pt_autoencoder(iwildcam_train_i_0_50_dl)\n",
    "                myTAE.init_detector(detector_type='{}'.format(i),reference_data=iwildcam_train_i_50_100,detector_name='iwildcam_TAE_{}_{}_{}'.format(size_training_set,size_remaining,i),save_dec=True)\n",
    "\n",
    "iwildcam_train_i_comp = None\n",
    "iwildcam_train_i = None\n",
    "iwildcam_train_i_0_50 = None \n",
    "iwildcam_train_i_50_100 = None\n",
    "iwildcam_train_i_dl = None\n",
    "myTAE = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['KS','CVM','MMD','LSDD']:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVM init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "iwildcam_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        iwildcam_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/iwildcam_v1.1/96_by_96_transform/iwildcam_96_train_ds.npz'.format(i))\n",
    "        iwildcam_train_i = iwildcam_train_i_comp['arr_0']\n",
    "        print(iwildcam_train_i.shape)\n",
    "\n",
    "        iwildcam_train_i_0_50 =  iwildcam_train_i[:iwildcam_MAX_TRAINING_SIZE]\n",
    "        print(iwildcam_train_i_0_50.shape)\n",
    "        \n",
    "        iwildcam_train_i_50_100 = iwildcam_train_i[iwildcam_MAX_TRAINING_SIZE:]\n",
    "        size_rest = iwildcam_train_i_50_100.shape[0]\n",
    "\n",
    "        iwildcam_train_i_0_50 = torch.as_tensor(iwildcam_train_i_0_50)\n",
    "        print(iwildcam_train_i_50_100.shape)\n",
    "        iwildcam_train_i_0_50_dl = DataLoader(TensorDataset(iwildcam_train_i_0_50,iwildcam_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(iwildcam_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='CVM',reference_data=iwildcam_train_i_50_100,detector_name='iwildcam_TAE_5000_{}_CVM'.format(size_rest),save_dec=True)\n",
    "\n",
    "        iwildcam_train_i_comp = None\n",
    "        iwildcam_train_i = None\n",
    "        iwildcam_train_i_0_50 = None \n",
    "        iwildcam_train_i_50_100 = None\n",
    "        iwildcam_train_i_dl = None\n",
    "        myTAE = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "iwildcam_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        iwildcam_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/iwildcam_v1.1/96_by_96_transform/iwildcam_96_train_ds.npz'.format(i))\n",
    "        iwildcam_train_i = iwildcam_train_i_comp['arr_0']\n",
    "        print(iwildcam_train_i.shape)\n",
    "\n",
    "        iwildcam_train_i_0_50 =  iwildcam_train_i[:iwildcam_MAX_TRAINING_SIZE]\n",
    "        print(iwildcam_train_i_0_50.shape)\n",
    "        \n",
    "        iwildcam_train_i_50_100 = iwildcam_train_i[iwildcam_MAX_TRAINING_SIZE:]\n",
    "        size_rest = iwildcam_train_i_50_100.shape[0]\n",
    "\n",
    "        iwildcam_train_i_0_50 = torch.as_tensor(iwildcam_train_i_0_50)\n",
    "        print(iwildcam_train_i_50_100.shape)\n",
    "        iwildcam_train_i_0_50_dl = DataLoader(TensorDataset(iwildcam_train_i_0_50,iwildcam_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(iwildcam_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='MMD',reference_data=iwildcam_train_i_50_100,detector_name='iwildcam_TAE_5000_{}_MMD'.format(size_rest),save_dec=True)\n",
    "\n",
    "        iwildcam_train_i_comp = None\n",
    "        iwildcam_train_i = None\n",
    "        iwildcam_train_i_0_50 = None \n",
    "        iwildcam_train_i_50_100 = None\n",
    "        iwildcam_train_i_dl = None\n",
    "        myTAE = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSDD init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "iwildcam_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        iwildcam_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/iwildcam_v1.1/iwildcam_train_{}_ds.npz'.format(i))\n",
    "        iwildcam_train_i = iwildcam_train_i_comp['arr_0']\n",
    "        print(iwildcam_train_i.shape)\n",
    "\n",
    "        iwildcam_train_i_0_50 =  iwildcam_train_i[:iwildcam_MAX_TRAINING_SIZE]\n",
    "        print(iwildcam_train_i_0_50.shape)\n",
    "        \n",
    "        iwildcam_train_i_50_100 = iwildcam_train_i[iwildcam_MAX_TRAINING_SIZE:]\n",
    "        size_rest = iwildcam_train_i_50_100.shape[0]\n",
    "\n",
    "        iwildcam_train_i_0_50 = torch.as_tensor(iwildcam_train_i_0_50)\n",
    "        print(iwildcam_train_i_50_100.shape)\n",
    "        iwildcam_train_i_0_50_dl = DataLoader(TensorDataset(iwildcam_train_i_0_50,iwildcam_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(iwildcam_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='LSDD',reference_data=iwildcam_train_i_50_100,detector_name='iwildcam_TAE_5000_{}_LSDD'.format(size_rest),save_dec=True)\n",
    "\n",
    "        iwildcam_train_i_comp = None\n",
    "        iwildcam_train_i = None\n",
    "        iwildcam_train_i_0_50 = None \n",
    "        iwildcam_train_i_50_100 = None\n",
    "        iwildcam_train_i_dl = None\n",
    "        myTAE = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibitorchwhy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "401cebfcb5cce5f71138843ad74eb16632e47d40b3a47aa4ad883b3d134173ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
