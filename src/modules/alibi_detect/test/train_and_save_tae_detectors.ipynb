{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace \\<Datasetname\\> for each Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KS init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "CAMELYON_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,105,5):\n",
    "        camelyon_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/camelyon17_v1.0/camelyon_train_{}_ds.npz'.format(i))\n",
    "        camelyon_train_i = camelyon_train_i_comp['arr_0']\n",
    "        print(camelyon_train_i.shape)\n",
    "\n",
    "        camelyon_train_i_0_50 =  camelyon_train_i[:CAMELYON_MAX_TRAINING_SIZE]\n",
    "        print(camelyon_train_i_0_50.shape)\n",
    "        \n",
    "        camelyon_train_i_50_100 = camelyon_train_i[CAMELYON_MAX_TRAINING_SIZE:]\n",
    "        size_rest = camelyon_train_i_50_100.shape[0]\n",
    "\n",
    "        camelyon_train_i_0_50 = torch.as_tensor(camelyon_train_i_0_50)\n",
    "        print(camelyon_train_i_50_100.shape)\n",
    "        camelyon_train_i_0_50_dl = DataLoader(TensorDataset(camelyon_train_i_0_50,camelyon_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(camelyon_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='KS',reference_data=camelyon_train_i_50_100,detector_name='camelyon_TAE_5000_{}_KS'.format(size_rest),save_dec=True)\n",
    "\n",
    "        camelyon_train_i_comp = None\n",
    "        camelyon_train_i = None\n",
    "        camelyon_train_i_0_50 = None \n",
    "        camelyon_train_i_50_100 = None\n",
    "        camelyon_train_i_dl = None\n",
    "        myTAE = None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVM init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/image-drift-monitoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 11:30:19.627486: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 11:30:19.748198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-14 11:30:19.748233: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-14 11:30:20.292211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 11:30:20.292281: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 11:30:20.292287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-14 11:30:22.549408: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-14 11:30:22.549443: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-14 11:30:22.549460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (render): /proc/driver/nvidia/version does not exist\n",
      "2023-02-14 11:30:22.550943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15121, 3, 96, 96)\n",
      "(5000, 3, 96, 96)\n",
      "(10121, 3, 96, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 157/157 [01:01<00:00,  2.57it/s, loss_ma=0.039] \n",
      "Epoch 2/5: 100%|██████████| 157/157 [01:02<00:00,  2.50it/s, loss_ma=0.0353]\n",
      "Epoch 3/5: 100%|██████████| 157/157 [01:10<00:00,  2.22it/s, loss_ma=0.0353]\n",
      "Epoch 4/5: 100%|██████████| 157/157 [01:06<00:00,  2.35it/s, loss_ma=0.0352]\n",
      "Epoch 5/5: 100%|██████████| 157/157 [01:18<00:00,  2.00it/s, loss_ma=0.0353]\n",
      "2023-02-14 11:36:08,078 [INFO]  CVM Detector initialized\n",
      "Directory /home/ubuntu/image-drift-monitoring/config/detectors/Camelyon/TAE/camelyon_TAE_5000_10121_CVM does not exist and is now created.\n",
      "Directory /home/ubuntu/image-drift-monitoring/config/detectors/Camelyon/TAE/camelyon_TAE_5000_10121_CVM/preprocess_fn does not exist and is now created.\n"
     ]
    }
   ],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "CAMELYON_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        camelyon_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/camelyon17_v1.0/camelyon_train_{}_ds.npz'.format(i))\n",
    "        camelyon_train_i = camelyon_train_i_comp['arr_0']\n",
    "        print(camelyon_train_i.shape)\n",
    "\n",
    "        camelyon_train_i_0_50 =  camelyon_train_i[:CAMELYON_MAX_TRAINING_SIZE]\n",
    "        print(camelyon_train_i_0_50.shape)\n",
    "        \n",
    "        camelyon_train_i_50_100 = camelyon_train_i[CAMELYON_MAX_TRAINING_SIZE:]\n",
    "        size_rest = camelyon_train_i_50_100.shape[0]\n",
    "\n",
    "        camelyon_train_i_0_50 = torch.as_tensor(camelyon_train_i_0_50)\n",
    "        print(camelyon_train_i_50_100.shape)\n",
    "        camelyon_train_i_0_50_dl = DataLoader(TensorDataset(camelyon_train_i_0_50,camelyon_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(camelyon_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='CVM',reference_data=camelyon_train_i_50_100,detector_name='camelyon_TAE_5000_{}_CVM'.format(size_rest),save_dec=True)\n",
    "\n",
    "        camelyon_train_i_comp = None\n",
    "        camelyon_train_i = None\n",
    "        camelyon_train_i_0_50 = None \n",
    "        camelyon_train_i_50_100 = None\n",
    "        camelyon_train_i_dl = None\n",
    "        myTAE = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/image-drift-monitoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 11:37:37.310460: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 11:37:37.430647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-14 11:37:37.430667: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-14 11:37:37.986168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 11:37:37.986235: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 11:37:37.986241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-14 11:37:40.256395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-14 11:37:40.256468: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-14 11:37:40.256487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (render): /proc/driver/nvidia/version does not exist\n",
      "2023-02-14 11:37:40.257502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15121, 3, 96, 96)\n",
      "(5000, 3, 96, 96)\n",
      "(10121, 3, 96, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 157/157 [00:57<00:00,  2.71it/s, loss_ma=0.038] \n",
      "Epoch 2/5: 100%|██████████| 157/157 [01:09<00:00,  2.27it/s, loss_ma=0.0355]\n",
      "Epoch 3/5: 100%|██████████| 157/157 [01:16<00:00,  2.04it/s, loss_ma=0.0354]\n",
      "Epoch 4/5: 100%|██████████| 157/157 [01:36<00:00,  1.63it/s, loss_ma=0.0353]\n",
      "Epoch 5/5: 100%|██████████| 157/157 [01:11<00:00,  2.18it/s, loss_ma=0.0352]\n",
      "2023-02-14 11:44:05,949 [INFO]  MMD Detector initialized\n",
      "Directory /home/ubuntu/image-drift-monitoring/config/detectors/Camelyon/TAE/camelyon_TAE_5000_10121_MMD does not exist and is now created.\n",
      "Directory /home/ubuntu/image-drift-monitoring/config/detectors/Camelyon/TAE/camelyon_TAE_5000_10121_MMD/preprocess_fn does not exist and is now created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...vars\n",
      "......0\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-14 11:44:05          343\n",
      "metadata.json                                  2023-02-14 11:44:05           64\n",
      "variables.h5                                   2023-02-14 11:44:05         4480\n"
     ]
    }
   ],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "CAMELYON_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        camelyon_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/camelyon17_v1.0/camelyon_train_{}_ds.npz'.format(i))\n",
    "        camelyon_train_i = camelyon_train_i_comp['arr_0']\n",
    "        print(camelyon_train_i.shape)\n",
    "\n",
    "        camelyon_train_i_0_50 =  camelyon_train_i[:CAMELYON_MAX_TRAINING_SIZE]\n",
    "        print(camelyon_train_i_0_50.shape)\n",
    "        \n",
    "        camelyon_train_i_50_100 = camelyon_train_i[CAMELYON_MAX_TRAINING_SIZE:]\n",
    "        size_rest = camelyon_train_i_50_100.shape[0]\n",
    "\n",
    "        camelyon_train_i_0_50 = torch.as_tensor(camelyon_train_i_0_50)\n",
    "        print(camelyon_train_i_50_100.shape)\n",
    "        camelyon_train_i_0_50_dl = DataLoader(TensorDataset(camelyon_train_i_0_50,camelyon_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(camelyon_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='MMD',reference_data=camelyon_train_i_50_100,detector_name='camelyon_TAE_5000_{}_MMD'.format(size_rest),save_dec=True)\n",
    "\n",
    "        camelyon_train_i_comp = None\n",
    "        camelyon_train_i = None\n",
    "        camelyon_train_i_0_50 = None \n",
    "        camelyon_train_i_50_100 = None\n",
    "        camelyon_train_i_dl = None\n",
    "        myTAE = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSDD init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/image-drift-monitoring\n",
      "(15121, 3, 96, 96)\n",
      "(5000, 3, 96, 96)\n",
      "(10121, 3, 96, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 157/157 [01:03<00:00,  2.46it/s, loss_ma=0.0393]\n",
      "Epoch 2/5: 100%|██████████| 157/157 [01:05<00:00,  2.41it/s, loss_ma=0.0355]\n",
      "Epoch 3/5: 100%|██████████| 157/157 [01:17<00:00,  2.03it/s, loss_ma=0.0353]\n",
      "Epoch 4/5: 100%|██████████| 157/157 [01:16<00:00,  2.04it/s, loss_ma=0.0352]\n",
      "Epoch 5/5: 100%|██████████| 157/157 [01:23<00:00,  1.88it/s, loss_ma=0.0353]\n",
      "2023-02-14 11:53:18,913 [INFO]  LSDD Detector initialized\n",
      "2023-02-14 11:53:18,913 [INFO]  LSDD Detector initialized\n",
      "Directory /home/ubuntu/image-drift-monitoring/config/detectors/Camelyon/TAE/camelyon_TAE_5000_10121_LSDD does not exist and is now created.\n",
      "Directory /home/ubuntu/image-drift-monitoring/config/detectors/Camelyon/TAE/camelyon_TAE_5000_10121_LSDD/preprocess_fn does not exist and is now created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...vars\n",
      "......0\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-14 11:53:18          343\n",
      "metadata.json                                  2023-02-14 11:53:18           64\n",
      "variables.h5                                   2023-02-14 11:53:18         4480\n"
     ]
    }
   ],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "CAMELYON_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        camelyon_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/camelyon17_v1.0/camelyon_train_{}_ds.npz'.format(i))\n",
    "        camelyon_train_i = camelyon_train_i_comp['arr_0']\n",
    "        print(camelyon_train_i.shape)\n",
    "\n",
    "        camelyon_train_i_0_50 =  camelyon_train_i[:CAMELYON_MAX_TRAINING_SIZE]\n",
    "        print(camelyon_train_i_0_50.shape)\n",
    "        \n",
    "        camelyon_train_i_50_100 = camelyon_train_i[CAMELYON_MAX_TRAINING_SIZE:]\n",
    "        size_rest = camelyon_train_i_50_100.shape[0]\n",
    "\n",
    "        camelyon_train_i_0_50 = torch.as_tensor(camelyon_train_i_0_50)\n",
    "        print(camelyon_train_i_50_100.shape)\n",
    "        camelyon_train_i_0_50_dl = DataLoader(TensorDataset(camelyon_train_i_0_50,camelyon_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(camelyon_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='LSDD',reference_data=camelyon_train_i_50_100,detector_name='camelyon_TAE_5000_{}_LSDD'.format(size_rest),save_dec=True)\n",
    "\n",
    "        camelyon_train_i_comp = None\n",
    "        camelyon_train_i = None\n",
    "        camelyon_train_i_0_50 = None \n",
    "        camelyon_train_i_50_100 = None\n",
    "        camelyon_train_i_dl = None\n",
    "        myTAE = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibitorchwhy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "401cebfcb5cce5f71138843ad74eb16632e47d40b3a47aa4ad883b3d134173ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
