{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace \\<Datasetname\\> for each Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KS init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "globalwheat_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/globalwheat_v1.1/96_by_96_transform/globalwheat_96_train_ds.npz')\n",
    "globalwheat_train_i = globalwheat_train_i_comp['arr_0']\n",
    "\n",
    "\n",
    "globalwheat_train_i_0_50 =  globalwheat_train_i[:int(globalwheat_train_i.shape[0]*0.5)]\n",
    "size_training_set = globalwheat_train_i_0_50.shape[0]\n",
    "\n",
    "globalwheat_train_i_50_100 = globalwheat_train_i[int(globalwheat_train_i.shape[0]*0.5):]\n",
    "size_remaining = globalwheat_train_i_50_100.shape[0]\n",
    "\n",
    "globalwheat_train_i_0_50 = torch.as_tensor(globalwheat_train_i_0_50)\n",
    "print(globalwheat_train_i_0_50.shape)\n",
    "print(globalwheat_train_i_50_100.shape)\n",
    "globalwheat_train_i_0_50_dl = DataLoader(TensorDataset(globalwheat_train_i_0_50,globalwheat_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "myTAE.init_default_pt_autoencoder(globalwheat_train_i_0_50_dl)\n",
    "myTAE.init_detector(detector_type='KS',reference_data=globalwheat_train_i_50_100,detector_name='globalwheat_TAE_{}_{}_KS'.format(size_training_set,size_remaining),save_dec=True)\n",
    "\n",
    "globalwheat_train_i_comp = None\n",
    "globalwheat_train_i = None\n",
    "globalwheat_train_i_0_50 = None \n",
    "globalwheat_train_i_50_100 = None\n",
    "globalwheat_train_i_dl = None\n",
    "myTAE = None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVM init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "globalwheat_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        globalwheat_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/globalwheat_v1.1/96_by_96_transform/globalwheat_96_train_ds.npz'.format(i))\n",
    "        globalwheat_train_i = globalwheat_train_i_comp['arr_0']\n",
    "        print(globalwheat_train_i.shape)\n",
    "\n",
    "        globalwheat_train_i_0_50 =  globalwheat_train_i[:globalwheat_MAX_TRAINING_SIZE]\n",
    "        print(globalwheat_train_i_0_50.shape)\n",
    "        \n",
    "        globalwheat_train_i_50_100 = globalwheat_train_i[globalwheat_MAX_TRAINING_SIZE:]\n",
    "        size_rest = globalwheat_train_i_50_100.shape[0]\n",
    "\n",
    "        globalwheat_train_i_0_50 = torch.as_tensor(globalwheat_train_i_0_50)\n",
    "        print(globalwheat_train_i_50_100.shape)\n",
    "        globalwheat_train_i_0_50_dl = DataLoader(TensorDataset(globalwheat_train_i_0_50,globalwheat_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(globalwheat_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='CVM',reference_data=globalwheat_train_i_50_100,detector_name='globalwheat_TAE_5000_{}_CVM'.format(size_rest),save_dec=True)\n",
    "\n",
    "        globalwheat_train_i_comp = None\n",
    "        globalwheat_train_i = None\n",
    "        globalwheat_train_i_0_50 = None \n",
    "        globalwheat_train_i_50_100 = None\n",
    "        globalwheat_train_i_dl = None\n",
    "        myTAE = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "globalwheat_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        globalwheat_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/globalwheat_v1.1/96_by_96_transform/globalwheat_96_train_ds.npz'.format(i))\n",
    "        globalwheat_train_i = globalwheat_train_i_comp['arr_0']\n",
    "        print(globalwheat_train_i.shape)\n",
    "\n",
    "        globalwheat_train_i_0_50 =  globalwheat_train_i[:globalwheat_MAX_TRAINING_SIZE]\n",
    "        print(globalwheat_train_i_0_50.shape)\n",
    "        \n",
    "        globalwheat_train_i_50_100 = globalwheat_train_i[globalwheat_MAX_TRAINING_SIZE:]\n",
    "        size_rest = globalwheat_train_i_50_100.shape[0]\n",
    "\n",
    "        globalwheat_train_i_0_50 = torch.as_tensor(globalwheat_train_i_0_50)\n",
    "        print(globalwheat_train_i_50_100.shape)\n",
    "        globalwheat_train_i_0_50_dl = DataLoader(TensorDataset(globalwheat_train_i_0_50,globalwheat_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(globalwheat_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='MMD',reference_data=globalwheat_train_i_50_100,detector_name='globalwheat_TAE_5000_{}_MMD'.format(size_rest),save_dec=True)\n",
    "\n",
    "        globalwheat_train_i_comp = None\n",
    "        globalwheat_train_i = None\n",
    "        globalwheat_train_i_0_50 = None \n",
    "        globalwheat_train_i_50_100 = None\n",
    "        globalwheat_train_i_dl = None\n",
    "        myTAE = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSDD init TAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  '/home/ubuntu/image-drift-monitoring'\n",
    "%pwd\n",
    "import numpy as np\n",
    "from src.modules.alibi_detect.trained_autoencoder import TrainedAutoencoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import json \n",
    "import torch\n",
    "\n",
    "\n",
    "with open('/home/ubuntu/image-drift-monitoring/config/common/drift_detection_config.json') as config_file:\n",
    "        drift_detection_config = json.load(config_file)\n",
    "\n",
    "globalwheat_MAX_TRAINING_SIZE = 5000\n",
    "\n",
    "for i in range(5,10,5):\n",
    "        globalwheat_train_i_comp = np.load('/home/ubuntu/image-drift-monitoring/data/globalwheat_v1.1/globalwheat_train_{}_ds.npz'.format(i))\n",
    "        globalwheat_train_i = globalwheat_train_i_comp['arr_0']\n",
    "        print(globalwheat_train_i.shape)\n",
    "\n",
    "        globalwheat_train_i_0_50 =  globalwheat_train_i[:globalwheat_MAX_TRAINING_SIZE]\n",
    "        print(globalwheat_train_i_0_50.shape)\n",
    "        \n",
    "        globalwheat_train_i_50_100 = globalwheat_train_i[globalwheat_MAX_TRAINING_SIZE:]\n",
    "        size_rest = globalwheat_train_i_50_100.shape[0]\n",
    "\n",
    "        globalwheat_train_i_0_50 = torch.as_tensor(globalwheat_train_i_0_50)\n",
    "        print(globalwheat_train_i_50_100.shape)\n",
    "        globalwheat_train_i_0_50_dl = DataLoader(TensorDataset(globalwheat_train_i_0_50,globalwheat_train_i_0_50),drift_detection_config['TAE']['BATCH_SIZE'],shuffle=True)\n",
    "\n",
    "        myTAE = TrainedAutoencoder(drift_detection_config)\n",
    "        myTAE.init_default_pt_autoencoder(globalwheat_train_i_0_50_dl)\n",
    "        myTAE.init_detector(detector_type='LSDD',reference_data=globalwheat_train_i_50_100,detector_name='globalwheat_TAE_5000_{}_LSDD'.format(size_rest),save_dec=True)\n",
    "\n",
    "        globalwheat_train_i_comp = None\n",
    "        globalwheat_train_i = None\n",
    "        globalwheat_train_i_0_50 = None \n",
    "        globalwheat_train_i_50_100 = None\n",
    "        globalwheat_train_i_dl = None\n",
    "        myTAE = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibitorchwhy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "401cebfcb5cce5f71138843ad74eb16632e47d40b3a47aa4ad883b3d134173ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
