{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate Summariesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "from whylogs.viz.utils import profile_viz_calculations\n",
    "\n",
    "def generate_summaries(\n",
    "    target_view: DatasetProfileView, ref_view: Optional[DatasetProfileView], config: Optional[SummaryConfig]\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    if config is None:\n",
    "        config = SummaryConfig()\n",
    "\n",
    "    if not target_view or not ref_view:\n",
    "        raise ValueError(\"This method has to get both target and reference profiles\")\n",
    "\n",
    "    overall_stats: OverallStats = add_overall_statistics(target_view)\n",
    "    drift_values = calculate_drift_values(target_view, ref_view)\n",
    "    # my testing\n",
    "    # print('Drift Values: \\n')\n",
    "    # print(drift_values)\n",
    "    # print('\\n')\n",
    "    target_col_views = target_view.get_columns()\n",
    "    ref_col_views = ref_view.get_columns()\n",
    "    ref_summary: DatasetSummary = {\"columns\": {}, \"properties\": overall_stats}\n",
    "    target_summary: DatasetSummary = {\"columns\": {}, \"properties\": None}\n",
    "    for target_col_name in target_col_views:\n",
    "        if target_col_name in ref_col_views and not is_image_compound_metric(target_col_views[target_col_name]):\n",
    "            target_column_summary: ColumnSummary = {\n",
    "                \"histogram\": None,\n",
    "                \"frequentItems\": None,\n",
    "                \"drift_from_ref\": None,\n",
    "                \"isDiscrete\": None,\n",
    "                \"featureStats\": None,\n",
    "            }\n",
    "            ref_column_summary: ColumnSummary = {\n",
    "                \"histogram\": None,\n",
    "                \"frequentItems\": None,\n",
    "                \"drift_from_ref\": None,\n",
    "                \"isDiscrete\": None,\n",
    "                \"featureStats\": None,\n",
    "            }\n",
    "\n",
    "            target_col_view = target_col_views[target_col_name]\n",
    "            ref_col_view = ref_col_views[target_col_name]\n",
    "            if not target_col_view or not ref_col_view:\n",
    "                continue\n",
    "\n",
    "            target_stats = add_feature_statistics(target_col_name, target_col_view)\n",
    "            target_column_summary[\"featureStats\"] = target_stats[target_col_name]\n",
    "\n",
    "            if target_col_name in drift_values:\n",
    "                col_drift_value = drift_values[target_col_name]\n",
    "                if col_drift_value:\n",
    "                    ref_column_summary[\"drift_from_ref\"] = col_drift_value[\"p_value\"]\n",
    "            target_dist = target_col_view.get_metric(\"distribution\")\n",
    "            reference_dist = ref_col_view.get_metric(\"distribution\")\n",
    "            if (\n",
    "                target_dist\n",
    "                and reference_dist\n",
    "                and not target_dist.kll.value.is_empty()\n",
    "                and not reference_dist.kll.value.is_empty()\n",
    "            ):\n",
    "                target_column_summary[\"isDiscrete\"] = ref_column_summary[\"isDiscrete\"] = False\n",
    "\n",
    "                target_histogram = histogram_from_view(target_col_view, target_col_name)\n",
    "                target_column_summary[\"histogram\"] = target_histogram\n",
    "\n",
    "                ref_histogram = histogram_from_view(ref_col_view, target_col_name)\n",
    "                ref_column_summary[\"histogram\"] = ref_histogram\n",
    "\n",
    "            elif target_col_view.get_metric(\"frequent_items\") and ref_col_view.get_metric(\"frequent_items\"):\n",
    "                target_column_summary[\"isDiscrete\"] = ref_column_summary[\"isDiscrete\"] = True\n",
    "\n",
    "                target_frequent_items = frequent_items_from_view(target_col_view, target_col_name, config)\n",
    "                target_column_summary[\"frequentItems\"] = target_frequent_items\n",
    "\n",
    "                ref_frequent_items = frequent_items_from_view(ref_col_view, target_col_name, config)\n",
    "                ref_column_summary[\"frequentItems\"] = ref_frequent_items\n",
    "            target_summary[\"columns\"][target_col_name] = target_column_summary\n",
    "            ref_summary[\"columns\"][target_col_name] = ref_column_summary\n",
    "\n",
    "    summaries = {\n",
    "        \"profile_from_whylogs\": json.dumps(target_summary),\n",
    "        \"reference_profile_from_whylogs\": json.dumps(ref_summary),\n",
    "    }\n",
    "    return summaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate drift values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "from whylogs.viz.utils import drift_calculations\n",
    "\n",
    "def calculate_drift_values(\n",
    "    target_view: DatasetProfileView, reference_view: DatasetProfileView, statistic=False\n",
    ") -> Dict[str, Optional[Union[ColumnDriftValue, ColumnDriftStatistic]]]:\n",
    "    \"\"\"Calculate drift values between both profiles. Applicable for numerical and categorical features.\n",
    "\n",
    "    Calculates drift only for features found in both profiles, and ignore those not found in either profile.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_view : DatasetProfileView\n",
    "        Target Profile View\n",
    "    reference_view : DatasetProfileView\n",
    "        Reference Profile View\n",
    "    statistic: bool\n",
    "        If false, value will be a pvalue. If true value will be a statistic.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    drift_values: Dict[str, Optional[ColumnDriftValue]]\n",
    "        A dictionary of the p-values, along with the type of test applied, for the given features.\n",
    "    \"\"\"\n",
    "    drift_values: Dict[str, Optional[Union[ColumnDriftValue, ColumnDriftStatistic]]] = {}\n",
    "    target_view_columns = target_view.get_columns()\n",
    "    reference_view_columns = reference_view.get_columns()\n",
    "    for target_column_name in target_view_columns:\n",
    "        if target_column_name in reference_view_columns:\n",
    "            target_view_column = target_view_columns[target_column_name]\n",
    "            reference_view_column = reference_view_columns[target_column_name]\n",
    "\n",
    "            if not statistic:\n",
    "                drift_values[target_column_name] = _get_ks_p_value(\n",
    "                    target_view_column=target_view_column, reference_view_column=reference_view_column\n",
    "                ) or _get_chi2_p_value(\n",
    "                    target_view_column=target_view_column, reference_view_column=reference_view_column\n",
    "                )\n",
    "            else:\n",
    "                drift_values[target_column_name] = _get_hellinger_distance(\n",
    "                    target_view_column=target_view_column, reference_view_column=reference_view_column\n",
    "                )\n",
    "    return drift_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_get_ks_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "from whylogs.viz.utils import drift_calculations\n",
    "\n",
    "def _get_ks_p_value(target_view_column, reference_view_column) -> Optional[ColumnDriftValue]:\n",
    "    target_dist_metric = target_view_column.get_metric(\"distribution\")\n",
    "    ref_dist_metric = reference_view_column.get_metric(\"distribution\")\n",
    "    # my testing\n",
    "    # test =  target_view_column.get_metric('image')\n",
    "    # if(test):\n",
    "    #     print('Submetrics : \\n', test.submetrics)\n",
    "    print('Target_Dist_metric: \\n')\n",
    "    print(target_dist_metric)\n",
    "    \n",
    "    if target_dist_metric is None or ref_dist_metric is None:\n",
    "        return None\n",
    "\n",
    "    target_kll_sketch = target_dist_metric.kll.value\n",
    "    ref_kll_sketch = ref_dist_metric.kll.value\n",
    "\n",
    "    ks_p_value = _compute_ks_test_p_value(target_kll_sketch, ref_kll_sketch)\n",
    "    return ks_p_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_compute_ks_test_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "from whylogs.viz.utils import drift_calculations\n",
    "\n",
    "def _compute_ks_test_p_value(\n",
    "    target_distribution: kll_doubles_sketch,\n",
    "    reference_distribution: kll_doubles_sketch,\n",
    "    quantiles: Optional[List[float]] = None,\n",
    ") -> Optional[ColumnDriftValue]:\n",
    "    \"\"\"Compute the Kolmogorov-Smirnov test p-value of two continuous distributions.\n",
    "\n",
    "    Uses the quantile values and the corresponding CDFs to calculate the approximate KS statistic.\n",
    "    Only applicable to continuous distributions.\n",
    "    The null hypothesis expects the samples to come from the same distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_distribution : datasketches.kll_floats_sketch\n",
    "        A kll_floats_sketch (quantiles sketch) from the target distribution's values\n",
    "    reference_distribution : datasketches.kll_floats_sketch\n",
    "        A kll_floats_sketch (quantiles sketch) from the reference (expected) distribution's values\n",
    "        Can be generated from a theoretical distribution, or another sample for the same feature.\n",
    "    quantiles: Optional[List[float]], optional\n",
    "        Bucket of quantiles used to get the CDF's for both target and reference profiles.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        p_value : float\n",
    "        The estimated p-value from the parametrized KS test, applied on the target and reference distributions'\n",
    "        kll_floats_sketch summaries\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if not quantiles:\n",
    "        QUANTILES = KSTestConfig().quantiles\n",
    "    else:\n",
    "        QUANTILES = quantiles\n",
    "\n",
    "    if reference_distribution.is_empty() or target_distribution.is_empty():\n",
    "        return None\n",
    "\n",
    "    D_max = 0\n",
    "    target_quantile_values = target_distribution.get_quantiles(QUANTILES)\n",
    "    ref_quantile_values = reference_distribution.get_quantiles(QUANTILES)\n",
    "\n",
    "    num_quantiles = len(QUANTILES)\n",
    "    i, j = 0, 0\n",
    "    while i < num_quantiles and j < num_quantiles:\n",
    "        if target_quantile_values[i] < ref_quantile_values[j]:\n",
    "            current_quantile = target_quantile_values[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            current_quantile = ref_quantile_values[j]\n",
    "            j += 1\n",
    "\n",
    "        cdf_target = target_distribution.get_cdf([current_quantile])[0]\n",
    "        cdf_ref = reference_distribution.get_cdf([current_quantile])[0]\n",
    "        D = abs(cdf_target - cdf_ref)\n",
    "        if D > D_max:\n",
    "            D_max = D\n",
    "\n",
    "    while i < num_quantiles:\n",
    "        cdf_target = target_distribution.get_cdf([target_quantile_values[i]])[0]\n",
    "        cdf_ref = reference_distribution.get_cdf([target_quantile_values[i]])[0]\n",
    "        D = abs(cdf_target - cdf_ref)\n",
    "        if D > D_max:\n",
    "            D_max = D\n",
    "        i += 1\n",
    "\n",
    "    while j < num_quantiles:\n",
    "        cdf_target = target_distribution.get_cdf([ref_quantile_values[j]])[0]\n",
    "        cdf_ref = reference_distribution.get_cdf([ref_quantile_values[j]])[0]\n",
    "        D = abs(cdf_target - cdf_ref)\n",
    "        if D > D_max:\n",
    "            D_max = D\n",
    "        j += 1\n",
    "\n",
    "    m, n = sorted([target_distribution.get_n(), reference_distribution.get_n()], reverse=True)\n",
    "    en = m * n / (m + n)\n",
    "\n",
    "    p_value = stats.distributions.kstwo.sf(D_max, np.round(en))\n",
    "\n",
    "    return {\"p_value\": p_value, \"test\": \"ks\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quantiles for KSTestConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "from whylogs.viz import configs\n",
    "\n",
    "# KSTestConfig --> quantiles\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "import numpy as np\n",
    "quantiles: List[float] = field(default_factory=lambda: list(np.linspace(0, 1, 100)))\n",
    "\n",
    "list(np.linspace(0,1,100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histogram_from_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "from whylogs.viz.utils import histogram_calculations\n",
    "\n",
    "def histogram_from_view(column_view: ColumnProfileView, feature_name: str) -> HistogramSummary:\n",
    "    col_dist: Optional[DistributionMetric] = column_view.get_metric(\"distribution\")\n",
    "    if not col_dist:\n",
    "        raise ValueError(\"Distribution Metrics not found for feature {}.\".format(feature_name))\n",
    "\n",
    "    target_kill = col_dist.kll.value\n",
    "    target_histogram = _histogram_from_sketch(target_kill)\n",
    "    return target_histogram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_histogram_from_sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "from whylogs.viz.utils import histogram_calculations\n",
    "\n",
    "def _histogram_from_sketch(\n",
    "    sketch: kll_doubles_sketch, max_buckets: int = None, avg_per_bucket: Optional[float] = None\n",
    ") -> HistogramSummary:\n",
    "    \"\"\"\n",
    "    Generate a summary of a kll_floats_sketch, including a histogram\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sketch : kll_floats_sketch\n",
    "        Data sketch\n",
    "    max_buckets : int\n",
    "        Override the default maximum number of buckets\n",
    "    avg_per_bucket : int\n",
    "        Override the default target number of items per bucket.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    histogram : HistogramSummary\n",
    "        Protobuf histogram message\n",
    "    \"\"\"\n",
    "    n = sketch.get_n()\n",
    "    start = sketch.get_min_value()\n",
    "    max_val = sketch.get_max_value()\n",
    "    end = max_val\n",
    "    if max_buckets is None:\n",
    "        max_buckets = MAX_HIST_BUCKETS\n",
    "    if avg_per_bucket is None:\n",
    "        avg_per_bucket = HIST_AVG_NUMBER_PER_BUCKET\n",
    "\n",
    "    if (n < 2) or (start == end):\n",
    "        dx = abs(start) * 1e-7\n",
    "        end = start + dx\n",
    "        bins = [start, end]\n",
    "        counts = [n]\n",
    "    else:\n",
    "        bins, end = _calculate_bins(end, start, n, avg_per_bucket, max_buckets)\n",
    "        pmf = sketch.get_pmf(bins)\n",
    "        counts = [round(p * n) for p in pmf]\n",
    "        counts = counts[1:-1]\n",
    "\n",
    "    histogram: HistogramSummary = {\n",
    "        \"start\": start,\n",
    "        \"end\": end,\n",
    "        \"width\": 0,\n",
    "        \"counts\": counts,\n",
    "        \"max\": max_val,\n",
    "        \"min\": start,\n",
    "        \"bins\": bins,\n",
    "        \"n\": n,\n",
    "    }\n",
    "    return histogram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "from whylogs.viz.utils import quantile_stats\n",
    "\n",
    "def _calculate_bins(\n",
    "    end: float, start: float, n: int, avg_per_bucket: float, max_buckets: int\n",
    ") -> Tuple[List[float], float]:\n",
    "    # Include the max value in the right-most bin\n",
    "    end += abs(end) * 1e-7\n",
    "    abs_end = abs(end)\n",
    "    abs_start = abs(start)\n",
    "\n",
    "    # Include the right edge in the bin edges\n",
    "    n_buckets = min(math.ceil(n / avg_per_bucket), max_buckets)\n",
    "    width = (end - start) / n_buckets\n",
    "\n",
    "    min_interval = _get_min_interval(abs_start, abs_end)\n",
    "\n",
    "    # If the bin width is smaller than min_interval, we need bigger bins\n",
    "    if width < min_interval:\n",
    "        n_buckets, width = _resize_bins(start, end, min_interval, width, n_buckets)\n",
    "\n",
    "    # Calculate histograms from the Probability Mass Function\n",
    "    bins = [start + i * width for i in range(n_buckets + 1)]\n",
    "    logger.debug(f\"about to get pmf using start: {start} end:{end} width:{width} and n_buckets:{n_buckets}\")\n",
    "    logger.debug(f\"bin: {bins}\")\n",
    "    return bins, end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whylogs_v1Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0 (default, Nov  6 2019, 21:49:08) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d07ef46bb94da80869bb5fdca6bcad36abde6f95401a7c8378292aba096a90fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
